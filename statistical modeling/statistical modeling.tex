\documentclass[11pt, twocolumn]{article}

\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\counterwithin*{section}{part}

\title{\textbf{Statistical Modeling}}
\author{}
\date{}


\begin{document}
\maketitle
\begin{abstract}
  Lo scopo del corso è riuscire a muoversi con dimestichezza all'interno di un dataset: è privilegiata la teoria perché indipendente dalla piattaforma; inoltre sono presentati numerosi esercizi svolti e database di esempio.
  Durante il corso si generalizza il modello lineare classico andando oltre alle sue premesse, arrivando al modello lineare multi-livello (che costruisce una gerarchia nei dati).

  L'esame è composto da una parte teorica di due domande (da un database di 15 note) e un esercizio da eseguire in R o SAS.
  Le slide sono sufficienti alla preparazione dell'esame, ma in più è offerta una dispensa ufficiale.
\end{abstract}

\newpage
\part{Premesse all'analisi}
Il modello stabilisce cosa fare coi dati: la finalità del modello stabilisce l'interpretazione da dare al risultato e i dati da raccogliere.
I test sul modello devono essere fatti su un campione \textit{significativo}: i risultati potrebbero non essere veritieri.
Il campione è necessario anche coi \textit{Big Data}, dato che aumentano l'eterogeneità dei dati.

Nella prima parte della costruzione del modello, lo statistico deve collaborare con l'esperto di dominio per individuare il fine del modello e i caratteri da osservare.
In un secondo momento si procede con un'analisi descrittiva (o esplorativa) del dataset (tramite grafici come istogrammi o boxplot, oppure calcolando valori indice).
Si individuano dunque gli \textit{outliers} (ovvero i valori anomali), da eliminare prima dell'analisi vera e propria.

Si analizza poi la matrice di correlazione $R$, per eliminare casi di \textit{multicollinearità} (ovvero i casi in cui la correlazione $\varrho \to 1$).

Si deve sciogliere il conflitto tra adattamento dei dati e parsimonia in modo tale da rendere comprensibile il modello ma garantendo una certa qualità nell'adattamento.

Il modello reale tiene conto dunque dell'errore, che considera cosa non è conoscibile e di componenti sistematici (esclusione di variabili) o di errori di misurazione; dai campioni (poco significativi) inoltre si può avere un errore stocastico.


Il modello statistico ha come scopo la comprensione e la minimizzazione dell'errore.
Non si arriva a formulare regole di causa-effetto ma solamente a relazioni empiriche.

Si stabilisce il modello di regressione individuando le variabili (e il loro grado) e il valore dei parametri nel vettore $b$.
Dunque si calcolano i valori stimati sui valori noti ($\hat{y_i}$) e si calcola l'errore con la formula $\varepsilon_i = y_i - \hat{y_i}$.
Al variare del campione nella popolazione, i valori dei parametri cambiano: è così possibile costruire una distribuzione (col metodo Montecarlo) di tali parametri.
L'errore dunque non è deterministico ma stocastico (cioè casuale), dato che varia in base al campione selezionato.

Il criterio scelto per ricercare $b$ è il criterio dei minimi quadrati ordinari che rende minima la norma del vettore di scarti $\varepsilon$.


\newpage
\part{Modello lineare classico}
Il modello lineare classico ha delle premesse molto rigide a causa della sua natura.
Si tratta perlopiù di \textit{ipotesi semplificatrici} che saranno rimosse con modelli più avanzati (tranne per le ultime due).
La formula è lineare:
\begin{equation*}
  y = Xb + \varepsilon
\end{equation*}

\subsection*{Linearità.}
Le variabili e i parametri del modello sono lineari.

\subsection*{Non sistematicità degli errori}
Il vettore casuale ha valore atteso nullo (altrimenti il nostro modello non è imparziale):
\begin{equation*}
  E(\varepsilon_i)=0, i = 1,\hdots,n 
\end{equation*}
% $E(\varepsilon|X)=0$
e quindi segue che:
\begin{align*}
  E(y | X) &= E(Xb + \varepsilon) \\
           &= Xb + E(\varepsilon) \\
           &= Xb + 0 = Xb
\end{align*}

\subsection*{Sfericità degli errori.}
Gli errori sono omoschedastici (cioè la varianza è costante) e non correlati:
\begin{align*}
  E(\varepsilon) &= E(y - Xb) \\
                 &= E(Xb - Xb) = 0
\end{align*}
e quindi:
\begin{align*}
  &var(\varepsilon_i) = E(\varepsilon_i^2) = \sigma_i^2 \\
  &cov(\varepsilon_i, \varepsilon_j) = E(\varepsilon_i\varepsilon_j) = 0)
\end{align*}
Di fatto molti casi reali sono correlati tra di loro (ovvero un'osservazione influenza le altre), come nella finanza, nelle serie temporali o nelle coordinate spaziali.

\subsection*{Non omoschedasticità.}
È una mera convenzione: si presume che la matrice del disegno $X$ sia fissa e nota di dimensione $n \times p+1$ ; questa astrazione garantisce una semplificazione del problema.
Le componenti non stocastiche sono riassunte dalla componente erratica.

\subsection*{Non stocasticità delle variabili esplicative}
I valori delle $x_j$ variabili esplicative non sono soggetti a fluttuazioni da campione a campione, perciò $E(X) = X$ e $Cov(X,\varepsilon) = 0$. La parte non fissa delle $x_j$ finisce in $\varepsilon$.

\subsection*{Normalità degli errori.}
Il soddisfacimento dell'ipotesi che $\varepsilon_i \sim N(0,\sigma^2)$ ovvero che la distribuzione dell’errore campionario sia normale provoca anche la normalità nella distribuzione di $y$ e di $\hat{\beta}$.
Questo permette la formulazione di test e la costruzione di intervalli di confidenza.


\subsection*{Non collinearità.}
Le variabili della matrice $X$ sono linearmente indipendenti. $X$ ha rango uguale al numero delle colonne (i caratteri, più una costante). Da ciò deriva che $X'X$ non è singolare: in caso contrario $X'X$ non è invertibile e il modello non risolvibile.

\subsection*{Numerosità della popolazione.}
Il numero di osservazioni è sempre maggiore del numero di caratteri osservati: $n \geq p + 1$.
Se questa proprietà non è soddisfatta, la matrice del disegno non è invertibile e dunque non è possibile la costruzione di alcun modello.


\section{Stima dei parametri.}
Per stimare i parametri, la formula matriciale è:
\begin{equation*}
  b = Hy = (X'X)^{-1}X' y
\end{equation*}

Si dice che uno stimatore è \textit{corretto} se il valore medio della sua distribuzione è pari a quello della popolazione ($E(\theta) = E(x)$).
Invece per \textit{consistenza} si intende che con una popolazione infinita il valore stimato sia quello della popolazione.
In sostanza:
\begin{equation*}
  \lim_{n\to\infty} Var(\hat{\theta}) = 0
\end{equation*}

Tra due (o più) stimatori è preferibile lo stimatore più \textit{efficiente}, ovvero con una varianza minore nella sua distribuzione.
Generalmente uno stimatore segue una distribuzione normale, supponiamo $\beta_j \sim N(\mu,\sigma^2)$ (ha una distribuzione normale), si effettua un test (con probabilità dell'errore di primo grado $\alpha$ arbitrario) per verificare la significatività di un parametro $\beta_j$ con varianza $\sigma$ nota:
\begin{align*}
  &P[-Z_{\frac{\alpha}{2}} < \frac{\beta_j}{\frac{\sigma}{\sqrt{n\sigma^{-1}_{j.j}}}} < +Z_{\frac{\alpha}{2}}] \\
  &= P[-Z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n\sigma^{-1}_{j.j}}} < \beta_j < Z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n\sigma^{-1}_{j.j}}}] = 1 - \alpha
\end{align*}
Solitamente nel modello lineare l'ipotesi nulla ($H_0$) è l'ipotesi che il parametro sia nullo $\beta_j \sim N(0,\sigma^2)$.

I test statistici per la significatività sono generalmente $F$ e $T$ (il primo è il quadrato del secondo) quando la varianza della popolazione $\sigma^2$ è ignota; nel caso invece di $\sigma^2$ nota allora è possibile sfruttare il test $Z$.

La distribuzione $T$ di Student è anche esplicitabile come:

\begin{align*}
\frac{Z}{\chi^2 * gdl}
\end{align*}

mentre la $F$ di Snedecor è riassumibile come:

\begin{align*}
\frac{\frac{SSE}{k}}{\frac{SSR}{n-k-1}}
\end{align*}

Nello specifico questa formula è sintetizzabile come il rapporto tra due distribuzioni $\chi^2$ ed i rispettivi gradi di libertà.

Oltre al test d'ipotesi per verificare la significatività dei parametri è possibile anche calcolare l'intervallo di confidenza di un parametro così da misurarne il possibile impatto.
\newline
\newline
La stima dei \textit{minimi quadrati ordinari (OLS)} e la \textit{stima di massima verosimiglianza} sono equivalenti poichè ricavano gli stessi valori per i parametri sfruttando due meccanismi differenti. Mentre la prima trova il valore dei parametri che minimizza la varianza, la seconda calcola i parametri che massimizzano la probabilità di osservare i valori da noi osservati. 

\section{Variabili nominali.}
Il sistema più diffuso per la gestione di variabili nominali è convertirle in \textit{dummys}: una serie di variabili fittizie con valore $0$ o $1$ in base al valore assunto dalla variabile.
In questo modo è possibile interpretare facilmente il risultato ottenuto.
Il numero di variabili dummy generate da un carattere qualitativo è pari a $v - 1$ (dove $v$ è il numero di possibili valori), per evitare multicollinearità; una variabile non è mai inserita.


\newpage
\part{Violazione delle ipotesi classiche}
Dato che ``tutti i modelli sono falsi'', le ipotesi classiche non sono scorrette, tuttavia semplificano in modo eccessivo: in circostanze reali è difficile trovare fenomeni che le soddisfino tutte.
Si possono però eliminare tutte le ipotesi classiche (a eccezione delle ultime due elencate precedentemente) in modo tale da ottenere un modello più veritiero.

\section{Residui eteroschedastici.}
La varianza dell'errore spesso dipende dalle variabili indipendenti: la distribuzione dell'errore è diversa per ogni osservazione.
Continuano a valere correttezza, linearità e consistenza:

\begin{align*}
  E(\hat{B}) &= E(Hy) \\
             &= H E(y) \\
             &= H E(Xb + e) \\
             &= H X E(b) + E(e) \\
             &= (X'X)^{-1}X'X E(b) + 0 = b
\end{align*}

La varianza tuttavia è maggiore:

\begin{align*}
  Var(\hat{B}) &= E((Hy - b)(Hy - b)') \\
               &= E((H(Xb + e) - b)(H(Xb + e) - b)') \\
\end{align*}

Ciò che non vale più, quindi, è l'efficienza: per questo motivo lo stimatore non è più considerabile BLUE. Questo avrà una conseguenza anche sui test d'ipotesi, per cui la regione di rifiuto diventerà molto più ampia, e per la stima degli intervalli di confidenza, che saranno più stretti e meno affidabili.

\subsection*{Come individuare l'eteroschedasticità.}
La violazione dell'ipotesi di eteroschedasticità è rilevabile attraverso due modalità: una di ispezione grafica ed una orientata verso dei test su misura.
Per quanto riguarda l'ispezione grafica, preferibile come primo approccio, è necessario ricorrere a visualizzazioni quale lo \textbf{Scatterplot}: con quest'ultimo è possibile mettere a confronto diverse coppie di elementi sugli assi, tutte egualmente valide.
\newline
Tra queste coppie abbiamo:
\begin{itemize}
\item $Y$ vs $X$
\item \textit{Residui stimati} vs $Y$\textit{predetta}
\item \textit{Residui al quadrato} vs \textit{Regressori}
\item \textit{Valori osservati} vs \textit{Valori predetti}
\item \textit{Residui} vs \textit{Regressori}
\end{itemize}
\end{document}